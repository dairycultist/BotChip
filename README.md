# BotChip

https://www.youtube.com/shorts/VLrRbZY5q3w

camera https://www.adafruit.com/product/5841

screen https://tronixstuff.com/2019/10/15/a-tiny-tiny-0-49-64-x-32-graphic-i2c-oled-display-with-arduino/

arduino emulator https://wokwi.com/arduino


1. just get something to work on an emulator
2. implement it in a bulky, easy way physically
3. cull it down to a default hardware spec; a "system on a chip" that has an arduino (nano?) processor, a tiny screen (that displays eyes when idle, and text when speaking), a camera, and a microphone (but no physical eyes or speaker or anything, but does have an I/O interface for auxilliaries) also custom PCB

what if I made an open source robo with hardware and AI software interacting with an abstraction layer for behaviours like eye-tracking and such

I wonder what's the simplest robot design that would evoke a "kinda alive feeling" response

responsiveness is pretty important

I bet if you stuck digital eyes onto a roomba that looked forward, unless it saw you, in which case it'd look at you, it'd feel pretty alive/emotive

research animation, since that's just Animating life right
